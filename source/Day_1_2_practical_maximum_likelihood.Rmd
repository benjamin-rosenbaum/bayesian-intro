---
title: "1.2 Practical: Maximum likelihood"
author: "Benjamin Rosenbaum"
date: "October 21, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup

```{r cars}
rm(list=ls())
library(manipulate)
set.seed(123) # initiate random number generator for reproducability
```

## Generate data

We draw sample data from a normal distribution.
```{r}
n=50
y = rnorm(n=n, mean=1.0, sd=2.0)

y
hist(y)
points(y, jitter(rep(0, times=n), factor=10))
```

## Statistical model, deterministic and stochastic part

statistical model: estimate mean and standard deviation
$$ y_i \sim \text{normal}(\mu, \sigma)$$ 

## The likelihood function 

The likelihood function for a single datapoint is the probability density function $$p(y_i|\mu,\sigma)=\frac{1}{\sqrt{2\pi\sigma}}\exp\left\{-\frac{(y_i-\mu)^2}{2\sigma^2}\right\}$$
For a single data point, the likelihood function `L` can be computed with the `dnorm()` function (for a given parameter combination $\mu$, $\sigma$).

```{r}
# likelihood of first data point:
i = 1
L = dnorm(x=y[i], mean=0, sd=1)
y[i]
L

# plot
curve(dnorm(x, mean=0, sd=1), from=-4, to=6, xlab="y", ylab="p(y)", ylim=c(0, 0.6))
points(y[i],0)
lines(c(y[i],y[i]), c(0, L), col="red")
lines(c(-50,y[i]), c(L, L), col="red")
```

For all datapoints, `dnorm()` can calculate all $p(y_i|\mu,\sigma)$ for given parameter combination $\mu$, $\sigma$ at once. `L` is a vector now.
```{r}
L = dnorm(x=y, mean=0, sd=1)
L
```

The likelihood function of all datapoints for a given parameter combination  $\mu$, $\sigma$ is the product of all single values
$$p(y_1,\dots,y_n|\mu,\sigma)=p(y_1|\mu,\sigma)\cdot \ldots \cdot p(y_n|\mu,\sigma)$$
This holds because observations are independent
```{r}
prod(L)
```

There is a problem. Each $p(y_i|\mu,\sigma)<1$. 

So multiplying them all results in an extremely small number. 

Better use 
$$
\begin{aligned}
\log p(y_1,\dots,y_n|\mu,\sigma) &= \log\left\{ p(y_1|\mu,\sigma)\cdot\ldots\cdot p(y_n|\mu,\sigma)  \right\} \\ 
&= \log p(y_1|\mu,\sigma) + \ldots + \log p(y_n|\mu,\sigma)
\end{aligned}
$$
log of a product is equal to sum of logs. 

We minimize the negative log likelihood (NLL) to find model parameters, which is equivalent to maximum likelihood (mathematical convention is minimization instead of maximization)
```{r}
-sum(log(L))
```


We can visualize the likelihood function of all datapoints for given parameters $\mu$ and $\sigma$.

You can play around with $\mu$ and $\sigma$. 

Which combination maximizes likelihood of all datapoints at once?
```{r, eval=FALSE}
curve.data <- function(mean, sd)
{
  curve(dnorm(x, mean=mean, sd=sd), from=-4, to=6, xlab="y", ylab="p(y)", ylim=c(0, 0.6))
  for(i in 1:n){
    lines(c(y[i],y[i]),c(0,dnorm(x=y[i], mean=mean, sd=sd)))
  }
}
manipulate(curve.data(mean, sd), 
           mean=slider(-3, 3, step=0.1, initial=0), 
           sd=slider(0.1,4, step=0.1, initial=1) )
```

```{r, eval=TRUE, echo=FALSE}
curve.data <- function(mean, sd)
{
  curve(dnorm(x, mean=mean, sd=sd), from=-4, to=6, xlab="y", ylab="p(y)", ylim=c(0, 0.6))
  for(i in 1:n){
    lines(c(y[i],y[i]),c(0,dnorm(x=y[i], mean=mean, sd=sd)))
  }
}
curve.data(0,1)
```

## Maximum likelihood with `optim()` 

We can use mathematical algorithms to search for the best parameter combination automatically. 

First, we define a function that directly calculates the NLL for the data and a given parameter combination

```{r}
nll.function = function(data, par){ 
  LL = dnorm(x=data, mean=par[1], sd=par[2], log=TRUE) # LL: log-likelihood
  NLL = -sum(LL) # nll: negative log likelihood
  return(NLL)
}
```

Example: for mu=0, sd=1

```{r}
nll.function(data=y, par=c(0.0, 1.0))
```

`optim()` function automatically searches for parameters that minimize the NLL

```{r}
optim(par=c(0.0, 1.0), # initial guess mu=0, sd=1
      fn=nll.function,
      data=y)
``` 

The maximum likelihood estimates are $\mu=1.068710$, $\sigma=1.833387$

